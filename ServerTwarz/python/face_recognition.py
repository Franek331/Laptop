#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
from deepface import DeepFace
from pathlib import Path
import os
import sys
import json
from PIL import Image
from PIL.ExifTags import TAGS

from config import (
    DEEPFACE_PRIMARY_MODEL,
    DEEPFACE_PRIMARY_THRESHOLD,
    DEEPFACE_SECONDARY_MODEL,
    DEEPFACE_SECONDARY_THRESHOLD,
    DEEPFACE_TERTIARY_MODEL,
    DEEPFACE_TERTIARY_THRESHOLD,
    PRIMARY_DIMENSIONS,
    SECONDARY_DIMENSIONS,
    TERTIARY_DIMENSIONS,
    FEATURE_EXTRACTION_ENABLED,
    FEATURE_WEIGHTS,
    FEATURE_THRESHOLD_MATCH,
    UPLOADS_DIR,
    DETECTOR_BACKEND,
    DETECTOR_ENFORCE,
    RECOGNITION_STRATEGY
)
from utils import (
    init_db,
    get_person_by_pesel,
    get_all_people,
    save_face_encoding,
    get_face_encoding,
    get_all_face_encodings,
    save_face_features,
    get_face_features,
    get_all_face_features,
    file_exists,
    get_full_path
)
from face_feature_analyzer import FaceFeatureAnalyzer


class FaceRecognizer:
    def __init__(self):
        """Inicjalizuj rozpoznawacz twarzy z wielomodelowÄ… analizÄ…"""
        print("\n" + "=" * 70)
        print("ğŸ§  Initializing Advanced Face Recognition System")
        print("=" * 70)

        init_db()
        self.feature_analyzer = FaceFeatureAnalyzer()

        # â­ MODELE - wszystkie z 128 wymiarami!
        self.models = [
            {
                'name': DEEPFACE_PRIMARY_MODEL,
                'threshold': DEEPFACE_PRIMARY_THRESHOLD,
                'dimensions': PRIMARY_DIMENSIONS
            },
            {
                'name': DEEPFACE_SECONDARY_MODEL,
                'threshold': DEEPFACE_SECONDARY_THRESHOLD,
                'dimensions': SECONDARY_DIMENSIONS
            },
            {
                'name': DEEPFACE_TERTIARY_MODEL,
                'threshold': DEEPFACE_TERTIARY_THRESHOLD,
                'dimensions': TERTIARY_DIMENSIONS
            }
        ]

        print(f"âœ… Primary Model: {self.models[0]['name']} (threshold: {self.models[0]['threshold']}, dims: {self.models[0]['dimensions']})")
        print(f"âœ… Secondary Model: {self.models[1]['name']} (threshold: {self.models[1]['threshold']}, dims: {self.models[1]['dimensions']})")
        print(f"âœ… Tertiary Model: {self.models[2]['name']} (threshold: {self.models[2]['threshold']}, dims: {self.models[2]['dimensions']})")
        print(f"ğŸ‘ï¸  Feature Analysis: ENABLED")
        print(f"ğŸ¯ Detector: {DETECTOR_BACKEND}")
        print(f"ğŸ“Š Feature Weights Configured")
        print("=" * 70 + "\n")

    @staticmethod
    def fix_image_rotation(image_path):
        """
        â­ Napraw rotacjÄ™ zdjÄ™cia ze aparatu
        Czyta metadane EXIF i obraca obraz jeÅ›li trzeba
        """
        try:
            print(f"ğŸ”§ Checking image rotation...")

            image = Image.open(image_path)

            # Odczytaj metadane EXIF
            exif = {}
            try:
                exif_data = image._getexif()
                if exif_data:
                    for tag_id, value in exif_data.items():
                        tag = TAGS.get(tag_id, tag_id)
                        exif[tag] = value

                    # Szukaj orientacji (tag 274)
                    orientation = exif.get('Orientation', 1)
                    print(f"   ğŸ“ EXIF Orientation: {orientation}")

                    # ObrÃ³t w zaleÅ¼noÅ›ci od orientacji
                    if orientation == 3:
                        print(f"   ğŸ”„ Rotating 180Â°")
                        image = image.rotate(180, expand=True)
                    elif orientation == 6:
                        print(f"   ğŸ”„ Rotating 270Â°")
                        image = image.rotate(270, expand=True)
                    elif orientation == 8:
                        print(f"   ğŸ”„ Rotating 90Â°")
                        image = image.rotate(90, expand=True)

                    # Zapisz poprawiony obraz
                    image.save(image_path)
                    print(f"   âœ… Image rotation fixed")

            except Exception as e:
                print(f"   âš ï¸ Could not read EXIF: {e}")

            image.close()

        except Exception as e:
            print(f"   âš ï¸ Error fixing rotation: {e}")

    def extract_face_encoding(self, image_path, model_name=None, expected_dimensions=None):
        """
        WyciÄ…gnij encoding twarzy ze zdjÄ™cia
        Zwraca: encoding (lista liczb) lub None
        
        Args:
            image_path: Å›cieÅ¼ka do zdjÄ™cia
            model_name: nazwa modelu (np. 'Facenet')
            expected_dimensions: oczekiwana liczba wymiarÃ³w
        """
        if model_name is None:
            model_name = DEEPFACE_PRIMARY_MODEL
        if expected_dimensions is None:
            expected_dimensions = PRIMARY_DIMENSIONS

        try:
            print(f"ğŸ“¸ Extracting encoding from: {image_path}")

            # Normalizuj Å›cieÅ¼kÄ™
            full_path = self._normalize_path(image_path)

            print(f"ğŸ“ Using path: {full_path}")
            print(f"âœ… File exists: {os.path.isfile(full_path)}")

            if not os.path.isfile(full_path):
                print(f"âŒ File not found: {full_path}")
                return None

            # â­ NAPRAW ROTACJÄ˜
            self.fix_image_rotation(full_path)

            # Odczytaj obraz
            image = cv2.imread(full_path)
            if image is None:
                print(f"âŒ Cannot read image: {full_path}")
                return None

            print(f"âœ… Image loaded successfully")

            # WyciÄ…gnij embedding za pomocÄ… DeepFace
            print(f"ğŸ§  Running DeepFace with model: {model_name}...")

            embedding = DeepFace.represent(
                img_path=full_path,
                model_name=model_name,
                enforce_detection=DETECTOR_ENFORCE,
                detector_backend=DETECTOR_BACKEND
            )

            if embedding and len(embedding) > 0:
                encoding = embedding[0]['embedding']
                print(f"âœ… Encoding extracted successfully ({len(encoding)} dimensions)")
                
                # â­ WALIDACJA WYMIARÃ“W
                if len(encoding) != expected_dimensions:
                    print(f"âš ï¸ WARNING: Expected {expected_dimensions} dims, got {len(encoding)}")
                    print(f"   Model {model_name} produces {len(encoding)}-dim encodings!")
                
                return encoding
            else:
                print(f"âŒ No face detected in image")
                # â­ FALLBACK: SprÃ³buj z enforce_detection=False
                print(f"ğŸ”„ Retrying with enforce_detection=False...")
                try:
                    embedding = DeepFace.represent(
                        img_path=full_path,
                        model_name=model_name,
                        enforce_detection=False,  # â† Klucz!
                        detector_backend=DETECTOR_BACKEND
                    )
                    if embedding and len(embedding) > 0:
                        encoding = embedding[0]['embedding']
                        print(f"âœ… Encoding extracted successfully with fallback ({len(encoding)} dimensions)")
                        return encoding
                except Exception as fallback_e:
                    print(f"âŒ Fallback also failed: {str(fallback_e)}")
                
                return None

        except Exception as e:
            print(f"âŒ Error extracting encoding with {model_name}: {str(e)}")
            # â­ FALLBACK NA EXCEPTION
            print(f"ğŸ”„ Retrying with enforce_detection=False...")
            try:
                embedding = DeepFace.represent(
                    img_path=full_path,
                    model_name=model_name,
                    enforce_detection=False,
                    detector_backend=DETECTOR_BACKEND
                )
                if embedding and len(embedding) > 0:
                    encoding = embedding[0]['embedding']
                    print(f"âœ… Encoding extracted successfully with fallback ({len(encoding)} dimensions)")
                    return encoding
            except Exception as fallback_e:
                print(f"âŒ Fallback also failed: {str(fallback_e)}")
            
            return None

    def register_person(self, pesel, photo_path):
        """
        Zarejestruj osobÄ™ - wyciÄ…gnij i zapisz encoding + cechy
        """
        try:
            print(f"\nğŸ“ Registering person: PESEL={pesel}")

            person = get_person_by_pesel(pesel)
            if not person:
                print(f"âŒ Person not found in database: {pesel}")
                return False

            full_path = get_full_path(photo_path)
            print(f"ğŸ“ Photo path: {full_path}")

            # â­ WYCIÄ„GNIJ ENCODING Z GÅÃ“WNEGO MODELU (z walidacjÄ… wymiarÃ³w)
            encoding = self.extract_face_encoding(
                full_path,
                DEEPFACE_PRIMARY_MODEL,
                PRIMARY_DIMENSIONS
            )
            if encoding is None:
                print(f"âŒ Failed to extract encoding for {pesel}")
                return False

            # â­ WYCIÄ„GNIJ CECHY SZCZEGÃ“LNE
            features = None
            if FEATURE_EXTRACTION_ENABLED:
                features = self.feature_analyzer.analyze_face_features(full_path)
                if features:
                    save_face_features(pesel, features)
                    print(f"âœ… Features saved")

            # Zapisz encoding w bazie
            success = save_face_encoding(pesel, encoding, DEEPFACE_PRIMARY_MODEL)

            if success:
                print(f"âœ… Person registered successfully: {person['first_name']} {person['last_name']}")
                if features:
                    print(f"   ğŸ‘ï¸  Eye color: {features.get('eye_color', {}).get('name', 'unknown')}")
                    print(f"   ğŸ’‡ Hair color: {features.get('hair_color', {}).get('name', 'unknown')}")
                    print(f"   ğŸ‘ƒ Nose width: {features.get('nose_width', {}).get('width_estimate', 'unknown')}")
                return True
            return False

        except Exception as e:
            print(f"âŒ Error registering person: {str(e)}")
            return False

    def recognize_face(self, image_path):
        """
        â­ NAPRAWIONA WERSJA - ZWRACA PIERWSZY MATCH ZARAZ
        
        Rozpoznaj twarz ze zdjÄ™cia - wielomodelowe porÃ³wnanie + analiza cech
        Zwraca: {Rozpoznano: bool, pesel, name, confidence, features, ...}
        
        Strategia:
        1. Model 1 (Primary) - najsurowszy, zwraca na pierwszy match
        2. JeÅ›li Model 1 fail â†’ Model 2 (Secondary)
        3. JeÅ›li Model 2 fail â†’ Model 3 (Tertiary)
        4. JeÅ›li wszystkie fail â†’ "Nie rozpoznano"
        """
        try:
            # Normalizuj Å›cieÅ¼kÄ™
            full_path = self._normalize_path(image_path)

            print(f"\n{'=' * 70}")
            print(f"ğŸ” RECOGNIZE FACE ENDPOINT")
            print(f"{'=' * 70}")
            print(f"Photo Path: {image_path}")
            print(f"ğŸ“ Full path: {full_path}")
            print(f"âœ… File exists: {os.path.isfile(full_path)}")

            if not os.path.isfile(full_path):
                print(f"âŒ File not found: {full_path}")
                return {
                    "Rozpoznano": False,
                    "Wiadomosc": "Plik nie znaleziony"
                }

            # â­ NAPRAW ROTACJÄ˜
            self.fix_image_rotation(full_path)

            # â­ WYCIÄ„GNIJ CECHY Z NIEZNANEGO ZDJÄ˜CIA
            query_features = None
            if FEATURE_EXTRACTION_ENABLED:
                print(f"ğŸ‘ï¸  Analyzing facial features...")
                query_features = self.feature_analyzer.analyze_face_features(full_path)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # â­ KLUCZOWA ZMIANA: PrÃ³buj modele po kolei
            # ZWRACA ZARAZ NA PIERWSZY MATCH!
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

            for model_config in self.models:
                model_name = model_config['name']
                threshold = model_config['threshold']
                expected_dims = model_config['dimensions']

                print(f"\nğŸ”„ Trying model: {model_name} (threshold: {threshold}, dims: {expected_dims})")

                # WyciÄ…gnij encoding
                query_encoding = self.extract_face_encoding(full_path, model_name, expected_dims)
                if query_encoding is None:
                    print(f"   âš ï¸ Could not extract encoding with {model_name}")
                    continue  # SprÃ³buj nastÄ™pny model

                # Pobierz wszystkie encodingi z bazy
                stored_encodings = get_all_face_encodings()

                if not stored_encodings:
                    print("   âš ï¸ No faces registered in database")
                    continue

                print(f"   ğŸ“Š Loaded {len(stored_encodings)} encodings from face_encodings table")
                print(f"   ğŸ” Comparing with {len(stored_encodings)} stored faces...")

                best_match = None
                best_distance = float('inf')

                # PorÃ³wnaj z kaÅ¼dym encodingiem w bazie
                for pesel, stored_encoding in stored_encodings.items():
                    try:
                        distance = self.calculate_distance(
                            np.array(query_encoding),
                            np.array(stored_encoding)
                        )

                        print(f"      ğŸ“Š {pesel}: distance = {distance:.4f}")

                        if distance < best_distance:
                            best_distance = distance
                            best_match = pesel

                    except ValueError as e:
                        print(f"      âš ï¸ {pesel}: Dimension mismatch - skipping")
                        continue

                # â­ KLUCZOWA ZMIANA: ZWRÃ“Ä† NA PIERWSZY MATCH!
                if best_match and best_distance < threshold:
                    print(f"\n   âœ… MATCH FOUND with {model_name}!")
                    print(f"      PESEL: {best_match}")
                    print(f"      Distance: {best_distance:.4f}")

                    person = get_person_by_pesel(best_match)

                    # Konwertuj dystans na pewnoÅ›Ä‡
                    confidence = 1 - (best_distance / threshold)
                    confidence = max(0, min(1, confidence))

                    # â­ ANALIZA CECH SZCZEGÃ“LNYCH
                    feature_score = 1.0
                    feature_details = {}

                    if FEATURE_EXTRACTION_ENABLED and query_features:
                        stored_features = get_face_features(best_match)
                        if stored_features:
                            feature_score = self._compare_features(
                                query_features,
                                stored_features
                            )
                            feature_details = {
                                'eye_color_match': query_features.get('eye_color', {}).get('name') == stored_features.get('eye_color', {}).get('name'),
                                'hair_color_match': query_features.get('hair_color', {}).get('name') == stored_features.get('hair_color', {}).get('name'),
                                'feature_similarity': feature_score
                            }
                            print(f"      ğŸ‘ï¸  Feature similarity: {feature_score:.2%}")

                    # PoÅ‚Ä…czony wynik
                    combined_score = (confidence * 0.7) + (feature_score * 0.3)

                    result = {
                        "Rozpoznano": True,
                        "Pesel": person['pesel'],
                        "Imie": person['first_name'],
                        "Nazwisko": person['last_name'],
                        "DataUrodzenia": person['date_of_birth'],
                        "Plec": person['gender'],
                        "Pewnosc": confidence,
                        "CechyWynik": feature_score,
                        "WynikPolaczony": combined_score,
                        "Model": model_name,
                        "Dystans": best_distance,
                        "SzczegolyCech": feature_details,
                        "Wiadomosc": f"Rozpoznano: {person['first_name']} {person['last_name']}"
                    }

                    # â­ NAJWAÅ»NIEJSZE: ZwrÃ³Ä‡ ZARAZ!
                    print(f"\nâœ… Returning result from model {model_name}")
                    print(f"{'=' * 70}\n")
                    return result

                else:
                    print(f"   âŒ NO MATCH with {model_name}")
                    if best_match:
                        print(f"      Best distance: {best_distance:.4f} (threshold: {threshold})")
                    else:
                        print(f"      No matches found in database")

            # â­ JeÅ›li Å»ADEN model nie znalazÅ‚ matcha
            print(f"\n{'=' * 70}")
            print(f"âŒ NO MATCH WITH ANY MODEL")
            print(f"{'=' * 70}\n")
            
            return {
                "Rozpoznano": False,
                "Pesel": None,
                "Imie": None,
                "Nazwisko": None,
                "Pewnosc": 0,
                "CechyWynik": 0,
                "Wiadomosc": "Twarz nie zostaÅ‚a rozpoznana - brak dopasowania z Å¼adnym modelem"
            }

        except Exception as e:
            print(f"âŒ Error recognizing face: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "Rozpoznano": False,
                "Wiadomosc": f"BÅ‚Ä…d: {str(e)}"
            }

    def _compare_features(self, features1: dict, features2: dict) -> float:
        """
        â­ PorÃ³wnaj cechy szczegÃ³lne dwÃ³ch twarzy
        Zwraca wynik podobieÅ„stwa (0-1)
        """
        total_weight = 0
        weighted_score = 0

        # PorÃ³wnaj kaÅ¼dÄ… cechÄ™
        for feature_name, weight in FEATURE_WEIGHTS.items():
            f1 = features1.get(feature_name)
            f2 = features2.get(feature_name)

            if f1 and f2:
                similarity = self._compare_single_feature(feature_name, f1, f2)
                weighted_score += similarity * weight
                total_weight += weight

        return weighted_score / total_weight if total_weight > 0 else 0

    @staticmethod
    def _compare_single_feature(feature_name: str, f1: dict, f2: dict) -> float:
        """
        PorÃ³wnaj pojedynczÄ… cechÄ™
        Zwraca podobieÅ„stwo (0-1)
        """
        if feature_name in ['eye_color', 'hair_color']:
            # PorÃ³wnaj nazwy kolorÃ³w
            if f1.get('name') == f2.get('name'):
                return 1.0
            # SprawdÅº podobieÅ„stwo RGB
            if 'rgb' in f1 and 'rgb' in f2:
                diff = np.sqrt(sum((a - b) ** 2 for a, b in zip(f1['rgb'], f2['rgb'])))
                return max(0, 1 - (diff / 255))
            return 0.5

        elif feature_name == 'eye_distance':
            # PorÃ³wnaj dystans miÄ™dzy oczami
            d1 = f1.get('normalized_distance')
            d2 = f2.get('normalized_distance')
            if d1 and d2:
                diff = abs(d1 - d2)
                return max(0, 1 - (diff * 5))  # 5% rÃ³Å¼nicy = 0.95
            return 0.5

        elif feature_name in ['nose_width', 'mouth_width']:
            # PorÃ³wnaj wymiary
            w1 = f1.get('width_pixels') or f1.get('width_estimate')
            w2 = f2.get('width_pixels') or f2.get('width_estimate')
            if w1 and w2:
                diff = abs(w1 - w2) / max(w1, w2)
                return max(0, 1 - diff)
            return 0.5

        elif feature_name == 'eyebrow_shape':
            # PorÃ³wnaj kÄ…t brwi
            a1 = f1.get('average_angle')
            a2 = f2.get('average_angle')
            if a1 is not None and a2 is not None:
                diff = abs(a1 - a2)
                return max(0, 1 - (diff / 45))  # 45Â° = 0
            return 0.5

        elif feature_name == 'facial_asymmetry':
            # PorÃ³wnaj asymetriÄ™
            s1 = f1.get('asymmetry_score', 0.5)
            s2 = f2.get('asymmetry_score', 0.5)
            diff = abs(s1 - s2)
            return max(0, 1 - diff)

        elif feature_name == 'skin_tone':
            # PorÃ³wnaj ton skÃ³ry
            t1 = f1.get('skin_tone', 'unknown')
            t2 = f2.get('skin_tone', 'unknown')
            if t1 == t2:
                return 1.0
            return 0.6

        return 0.5

    @staticmethod
    def _normalize_path(image_path):
        """Normalizuj Å›cieÅ¼kÄ™ do pliku"""
        if image_path.startswith('/uploads/'):
            return os.path.abspath(
                os.path.join(
                    os.path.dirname(__file__),
                    '../uploads/',
                    image_path.replace('/uploads/', '')
                )
            )
        elif image_path.startswith('/'):
            return image_path
        else:
            return os.path.abspath(
                os.path.join(os.path.dirname(__file__), '..', image_path)
            )

    @staticmethod
    def calculate_distance(encoding1, encoding2):
        """
        Oblicz dystans Euklidesowy miÄ™dzy dwoma encodingami
        
        â­ OBSÅUGUJE RÃ“Å»NE WYMIARY - przycina do mniejszego wymiaru
        WartoÅ›ci bliskie 0 = bardzo podobne
        """
        if len(encoding1) != len(encoding2):
            print(f"âš ï¸ WARNING: Dimension mismatch - {len(encoding1)} vs {len(encoding2)}")
            # Przycina do mniejszego wymiaru
            min_dim = min(len(encoding1), len(encoding2))
            encoding1 = encoding1[:min_dim]
            encoding2 = encoding2[:min_dim]
            print(f"âœ‚ï¸ Truncated to {min_dim} dimensions")
        
        return np.linalg.norm(encoding1 - encoding2)


def main():
    """GÅ‚Ã³wna funkcja do testowania"""
    print("\nğŸ­ Advanced Face Recognition System - Test Mode\n")

    # Inicjalizuj rozpoznawacz
    recognizer = FaceRecognizer()

    # Pobierz argumenty z linii poleceÅ„
    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "register" and len(sys.argv) > 3:
            pesel = sys.argv[2]
            photo_path = sys.argv[3]
            result = recognizer.register_person(pesel, photo_path)
            print(json.dumps({"success": result}))

        elif command == "recognize" and len(sys.argv) > 2:
            image_path = sys.argv[2]
            result = recognizer.recognize_face(image_path)
            print(json.dumps(result, default=str))

        else:
            print("Usage:")
            print("  python face_recognition.py register <pesel> <photo_path>")
            print("  python face_recognition.py recognize <image_path>")
    else:
        print("Usage:")
        print("  python face_recognition.py register <pesel> <photo_path>")
        print("  python face_recognition.py recognize <image_path>")


if __name__ == "__main__":
    main()