#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
from deepface import DeepFace
from pathlib import Path
import os
import sys
import json
from PIL import Image
from PIL.ExifTags import TAGS

from config import (
    DEEPFACE_PRIMARY_MODEL,
    DEEPFACE_PRIMARY_THRESHOLD,
    DEEPFACE_SECONDARY_MODEL,
    DEEPFACE_SECONDARY_THRESHOLD,
    DEEPFACE_TERTIARY_MODEL,
    DEEPFACE_TERTIARY_THRESHOLD,
    PRIMARY_DIMENSIONS,
    SECONDARY_DIMENSIONS,
    TERTIARY_DIMENSIONS,
    FEATURE_EXTRACTION_ENABLED,
    FEATURE_WEIGHTS,
    FEATURE_THRESHOLD_MATCH,
    UPLOADS_DIR,
    DETECTOR_BACKEND,
    DETECTOR_ENFORCE,
    RECOGNITION_STRATEGY
)
from utils import (
    init_db,
    get_person_by_pesel,
    get_all_people,
    save_face_encoding,
    get_face_encoding,
    get_all_face_encodings,
    save_face_features,
    get_face_features,
    get_all_face_features,
    file_exists,
    get_full_path
)
from face_feature_analyzer import FaceFeatureAnalyzer


class FaceRecognizer:
    def __init__(self):
        """Inicjalizuj rozpoznawacz twarzy z wielomodelowƒÖ analizƒÖ"""
        print("\n" + "=" * 70)
        print("üß† Initializing Advanced Face Recognition System")
        print("=" * 70)

        init_db()
        self.feature_analyzer = FaceFeatureAnalyzer()

        # ‚≠ê MODELE - wszystkie z 128 wymiarami!
        self.models = [
            {
                'name': DEEPFACE_PRIMARY_MODEL,
                'threshold': DEEPFACE_PRIMARY_THRESHOLD,
                'dimensions': PRIMARY_DIMENSIONS
            },
            {
                'name': DEEPFACE_SECONDARY_MODEL,
                'threshold': DEEPFACE_SECONDARY_THRESHOLD,
                'dimensions': SECONDARY_DIMENSIONS
            },
            {
                'name': DEEPFACE_TERTIARY_MODEL,
                'threshold': DEEPFACE_TERTIARY_THRESHOLD,
                'dimensions': TERTIARY_DIMENSIONS
            }
        ]

        print(f"‚úÖ Primary Model: {self.models[0]['name']} (threshold: {self.models[0]['threshold']}, dims: {self.models[0]['dimensions']})")
        print(f"‚úÖ Secondary Model: {self.models[1]['name']} (threshold: {self.models[1]['threshold']}, dims: {self.models[1]['dimensions']})")
        print(f"‚úÖ Tertiary Model: {self.models[2]['name']} (threshold: {self.models[2]['threshold']}, dims: {self.models[2]['dimensions']})")
        print(f"üëÅÔ∏è  Feature Analysis: ENABLED")
        print(f"üéØ Detector: {DETECTOR_BACKEND}")
        print(f"üìä Feature Weights Configured")
        print("=" * 70 + "\n")

    @staticmethod
    def fix_image_rotation(image_path):
        """
        ‚≠ê Napraw rotacjƒô zdjƒôcia ze aparatu
        Czyta metadane EXIF i obraca obraz je≈õli trzeba
        """
        try:
            print(f"üîß Checking image rotation...")

            image = Image.open(image_path)

            # Odczytaj metadane EXIF
            exif = {}
            try:
                exif_data = image._getexif()
                if exif_data:
                    for tag_id, value in exif_data.items():
                        tag = TAGS.get(tag_id, tag_id)
                        exif[tag] = value

                    # Szukaj orientacji (tag 274)
                    orientation = exif.get('Orientation', 1)
                    print(f"   üìê EXIF Orientation: {orientation}")

                    # Obr√≥t w zale≈ºno≈õci od orientacji
                    if orientation == 3:
                        print(f"   üîÑ Rotating 180¬∞")
                        image = image.rotate(180, expand=True)
                    elif orientation == 6:
                        print(f"   üîÑ Rotating 270¬∞")
                        image = image.rotate(270, expand=True)
                    elif orientation == 8:
                        print(f"   üîÑ Rotating 90¬∞")
                        image = image.rotate(90, expand=True)

                    # Zapisz poprawiony obraz
                    image.save(image_path)
                    print(f"   ‚úÖ Image rotation fixed")

            except Exception as e:
                print(f"   ‚ö†Ô∏è Could not read EXIF: {e}")

            image.close()

        except Exception as e:
            print(f"   ‚ö†Ô∏è Error fixing rotation: {e}")

    def extract_face_encoding(self, image_path, model_name=None, expected_dimensions=None):
        """
        WyciƒÖgnij encoding twarzy ze zdjƒôcia
        Zwraca: encoding (lista liczb) lub None
        
        Args:
            image_path: ≈õcie≈ºka do zdjƒôcia
            model_name: nazwa modelu (np. 'Facenet')
            expected_dimensions: oczekiwana liczba wymiar√≥w
        """
        if model_name is None:
            model_name = DEEPFACE_PRIMARY_MODEL
        if expected_dimensions is None:
            expected_dimensions = PRIMARY_DIMENSIONS

        try:
            print(f"üì∏ Extracting encoding from: {image_path}")

            # Normalizuj ≈õcie≈ºkƒô
            full_path = self._normalize_path(image_path)

            print(f"üìÅ Using path: {full_path}")
            print(f"‚úÖ File exists: {os.path.isfile(full_path)}")

            if not os.path.isfile(full_path):
                print(f"‚ùå File not found: {full_path}")
                return None

            # ‚≠ê NAPRAW ROTACJƒò
            self.fix_image_rotation(full_path)

            # Odczytaj obraz
            image = cv2.imread(full_path)
            if image is None:
                print(f"‚ùå Cannot read image: {full_path}")
                return None

            print(f"‚úÖ Image loaded successfully")

            # WyciƒÖgnij embedding za pomocƒÖ DeepFace
            print(f"üß† Running DeepFace with model: {model_name}...")

            embedding = DeepFace.represent(
                img_path=full_path,
                model_name=model_name,
                enforce_detection=DETECTOR_ENFORCE,
                detector_backend=DETECTOR_BACKEND
            )

            if embedding and len(embedding) > 0:
                encoding = embedding[0]['embedding']
                print(f"‚úÖ Encoding extracted successfully ({len(encoding)} dimensions)")
                
                # ‚≠ê WALIDACJA WYMIAR√ìW
                if len(encoding) != expected_dimensions:
                    print(f"‚ö†Ô∏è WARNING: Expected {expected_dimensions} dims, got {len(encoding)}")
                    print(f"   Model {model_name} produces {len(encoding)}-dim encodings!")
                
                return encoding
            else:
                print(f"‚ùå No face detected in image")
                return None

        except Exception as e:
            print(f"‚ùå Error extracting encoding with {model_name}: {str(e)}")
            return None

    def register_person(self, pesel, photo_path):
        """
        Zarejestruj osobƒô - wyciƒÖgnij i zapisz encoding + cechy
        """
        try:
            print(f"\nüìù Registering person: PESEL={pesel}")

            person = get_person_by_pesel(pesel)
            if not person:
                print(f"‚ùå Person not found in database: {pesel}")
                return False

            full_path = get_full_path(photo_path)
            print(f"üìÅ Photo path: {full_path}")

            # ‚≠ê WYCIƒÑGNIJ ENCODING Z G≈Å√ìWNEGO MODELU (z walidacjƒÖ wymiar√≥w)
            encoding = self.extract_face_encoding(
                full_path,
                DEEPFACE_PRIMARY_MODEL,
                PRIMARY_DIMENSIONS
            )
            if encoding is None:
                print(f"‚ùå Failed to extract encoding for {pesel}")
                return False

            # ‚≠ê WYCIƒÑGNIJ CECHY SZCZEG√ìLNE
            features = None
            if FEATURE_EXTRACTION_ENABLED:
                features = self.feature_analyzer.analyze_face_features(full_path)
                if features:
                    save_face_features(pesel, features)
                    print(f"‚úÖ Features saved")

            # Zapisz encoding w bazie
            success = save_face_encoding(pesel, encoding, DEEPFACE_PRIMARY_MODEL)

            if success:
                print(f"‚úÖ Person registered successfully: {person['first_name']} {person['last_name']}")
                if features:
                    print(f"   üëÅÔ∏è  Eye color: {features.get('eye_color', {}).get('name', 'unknown')}")
                    print(f"   üíá Hair color: {features.get('hair_color', {}).get('name', 'unknown')}")
                    print(f"   üëÉ Nose width: {features.get('nose_width', {}).get('width_estimate', 'unknown')}")
                return True
            return False

        except Exception as e:
            print(f"‚ùå Error registering person: {str(e)}")
            return False

    def recognize_face(self, image_path):
        """
        Rozpoznaj twarz ze zdjƒôcia - wielomodelowe por√≥wnanie + analiza cech
        Zwraca: {found: bool, pesel, name, confidence, features, ...}
        
        ‚≠ê WA≈ªNE: Ta funkcja teraz obs≈Çuguje kompatybilne wymiary!
        """
        try:
            print(f"\nüîç Recognizing face from: {image_path}")

            # Normalizuj ≈õcie≈ºkƒô
            full_path = self._normalize_path(image_path)

            print(f"üìÅ Full path: {full_path}")
            print(f"‚úÖ File exists: {os.path.isfile(full_path)}")

            if not os.path.isfile(full_path):
                print(f"‚ùå File not found: {full_path}")
                return {
                    "Rozpoznano": False,
                    "Wiadomosc": "Plik nie znaleziony"
                }

            # ‚≠ê NAPRAW ROTACJƒò
            self.fix_image_rotation(full_path)

            # ‚≠ê WYCIƒÑGNIJ CECHY Z NIEZNANEGO ZDJƒòCIA
            query_features = None
            if FEATURE_EXTRACTION_ENABLED:
                query_features = self.feature_analyzer.analyze_face_features(full_path)

            # Spr√≥buj z ka≈ºdym modelem po kolei
            best_result = None
            best_score = 0

            for model_config in self.models:
                model_name = model_config['name']
                threshold = model_config['threshold']
                expected_dims = model_config['dimensions']

                print(f"\nüîÑ Trying model: {model_name} (threshold: {threshold}, dims: {expected_dims})")

                # WyciƒÖgnij encoding z WALIDACJƒÑ wymiar√≥w
                query_encoding = self.extract_face_encoding(full_path, model_name, expected_dims)
                if query_encoding is None:
                    print(f"   ‚ö†Ô∏è Could not extract encoding with {model_name}")
                    continue

                # Pobierz wszystkie encodingi z bazy
                stored_encodings = get_all_face_encodings()

                if not stored_encodings:
                    print("   ‚ö†Ô∏è No faces registered in database")
                    continue

                print(f"   üîé Comparing with {len(stored_encodings)} stored faces...")

                best_match = None
                best_distance = float('inf')

                # Por√≥wnaj z ka≈ºdym encodingiem w bazie
                for pesel, stored_encoding in stored_encodings.items():
                    try:
                        # ‚≠ê OBS≈ÅUGA R√ì≈ªNYCH WYMIAR√ìW
                        distance = self.calculate_distance(
                            np.array(query_encoding),
                            np.array(stored_encoding)
                        )

                        print(f"      üìä {pesel}: distance = {distance:.4f}")

                        if distance < best_distance:
                            best_distance = distance
                            best_match = pesel
                    
                    except ValueError as e:
                        # Wymiary siƒô nie zgadzajƒÖ - przejd≈∫ do kolejnego
                        print(f"      ‚ö†Ô∏è {pesel}: Dimension mismatch - skipping")
                        continue

                # Sprawd≈∫ czy dystans jest poni≈ºej progu dla tego modelu
                if best_match and best_distance < threshold:
                    print(f"\n   ‚úÖ MATCH FOUND with {model_name}!")
                    print(f"      PESEL: {best_match}")
                    print(f"      Distance: {best_distance:.4f}")

                    person = get_person_by_pesel(best_match)

                    # Konwertuj dystans na pewno≈õƒá
                    confidence = 1 - (best_distance / threshold)
                    confidence = max(0, min(1, confidence))

                    # ‚≠ê ANALIZA CECH SZCZEG√ìLNYCH
                    feature_score = 1.0
                    feature_details = {}

                    if FEATURE_EXTRACTION_ENABLED and query_features:
                        stored_features = get_face_features(best_match)
                        if stored_features:
                            feature_score = self._compare_features(
                                query_features,
                                stored_features
                            )
                            feature_details = {
                                'eye_color_match': query_features.get('eye_color', {}).get('name') == stored_features.get('eye_color', {}).get('name'),
                                'hair_color_match': query_features.get('hair_color', {}).get('name') == stored_features.get('hair_color', {}).get('name'),
                                'feature_similarity': feature_score
                            }
                            print(f"      üëÅÔ∏è  Feature similarity: {feature_score:.2%}")

                    # Po≈ÇƒÖczony wynik
                    combined_score = (confidence * 0.7) + (feature_score * 0.3)

                    result = {
                        "Rozpoznano": True,
                        "Pesel": person['pesel'],
                        "Imie": person['first_name'],
                        "Nazwisko": person['last_name'],
                        "DataUrodzenia": person['date_of_birth'],
                        "Plec": person['gender'],
                        "Pewnosc": confidence,
                        "CechyWynik": feature_score,
                        "WynikPolaczony": combined_score,
                        "Model": model_name,
                        "Dystans": best_distance,
                        "SzczegolyCech": feature_details,
                        "Wiadomosc": f"Rozpoznano: {person['first_name']} {person['last_name']}"
                    }

                    if combined_score > best_score:
                        best_score = combined_score
                        best_result = result

                else:
                    print(f"\n   ‚ùå NO MATCH with {model_name}")
                    if best_match:
                        print(f"      Best distance: {best_distance:.4f} (threshold: {threshold})")
                    else:
                        print(f"      No matches found")

            # Zwr√≥ƒá najlepszy wynik ze wszystkich modeli
            if best_result:
                return best_result
            else:
                return {
                    "Rozpoznano": False,
                    "Pesel": None,
                    "Imie": None,
                    "Nazwisko": None,
                    "Pewnosc": 0,
                    "CechyWynik": 0,
                    "Wiadomosc": "Twarz nie zosta≈Ça rozpoznana"
                }

        except Exception as e:
            print(f"‚ùå Error recognizing face: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "Rozpoznano": False,
                "Wiadomosc": f"B≈ÇƒÖd: {str(e)}"
            }

    def _compare_features(self, features1: dict, features2: dict) -> float:
        """
        ‚≠ê Por√≥wnaj cechy szczeg√≥lne dw√≥ch twarzy
        Zwraca wynik podobie≈Ñstwa (0-1)
        """
        total_weight = 0
        weighted_score = 0

        # Por√≥wnaj ka≈ºdƒÖ cechƒô
        for feature_name, weight in FEATURE_WEIGHTS.items():
            f1 = features1.get(feature_name)
            f2 = features2.get(feature_name)

            if f1 and f2:
                similarity = self._compare_single_feature(feature_name, f1, f2)
                weighted_score += similarity * weight
                total_weight += weight

        return weighted_score / total_weight if total_weight > 0 else 0

    @staticmethod
    def _compare_single_feature(feature_name: str, f1: dict, f2: dict) -> float:
        """
        Por√≥wnaj pojedynczƒÖ cechƒô
        Zwraca podobie≈Ñstwo (0-1)
        """
        if feature_name in ['eye_color', 'hair_color']:
            # Por√≥wnaj nazwy kolor√≥w
            if f1.get('name') == f2.get('name'):
                return 1.0
            # Sprawd≈∫ podobie≈Ñstwo RGB
            if 'rgb' in f1 and 'rgb' in f2:
                diff = np.sqrt(sum((a - b) ** 2 for a, b in zip(f1['rgb'], f2['rgb'])))
                return max(0, 1 - (diff / 255))
            return 0.5

        elif feature_name == 'eye_distance':
            # Por√≥wnaj dystans miƒôdzy oczami
            d1 = f1.get('normalized_distance')
            d2 = f2.get('normalized_distance')
            if d1 and d2:
                diff = abs(d1 - d2)
                return max(0, 1 - (diff * 5))  # 5% r√≥≈ºnicy = 0.95
            return 0.5

        elif feature_name in ['nose_width', 'mouth_width']:
            # Por√≥wnaj wymiary
            w1 = f1.get('width_pixels') or f1.get('width_estimate')
            w2 = f2.get('width_pixels') or f2.get('width_estimate')
            if w1 and w2:
                diff = abs(w1 - w2) / max(w1, w2)
                return max(0, 1 - diff)
            return 0.5

        elif feature_name == 'eyebrow_shape':
            # Por√≥wnaj kƒÖt brwi
            a1 = f1.get('average_angle')
            a2 = f2.get('average_angle')
            if a1 is not None and a2 is not None:
                diff = abs(a1 - a2)
                return max(0, 1 - (diff / 45))  # 45¬∞ = 0
            return 0.5

        elif feature_name == 'facial_asymmetry':
            # Por√≥wnaj asymetriƒô
            s1 = f1.get('asymmetry_score', 0.5)
            s2 = f2.get('asymmetry_score', 0.5)
            diff = abs(s1 - s2)
            return max(0, 1 - diff)

        elif feature_name == 'skin_tone':
            # Por√≥wnaj ton sk√≥ry
            t1 = f1.get('skin_tone', 'unknown')
            t2 = f2.get('skin_tone', 'unknown')
            if t1 == t2:
                return 1.0
            return 0.6

        return 0.5

    @staticmethod
    def _normalize_path(image_path):
        """Normalizuj ≈õcie≈ºkƒô do pliku"""
        if image_path.startswith('/uploads/'):
            return os.path.abspath(
                os.path.join(
                    os.path.dirname(__file__),
                    '../uploads/',
                    image_path.replace('/uploads/', '')
                )
            )
        elif image_path.startswith('/'):
            return image_path
        else:
            return os.path.abspath(
                os.path.join(os.path.dirname(__file__), '..', image_path)
            )

    @staticmethod
    def calculate_distance(encoding1, encoding2):
        """
        Oblicz dystans Euklidesowy miƒôdzy dwoma encodingami
        
        ‚≠ê OBS≈ÅUGUJE R√ì≈ªNE WYMIARY - przycina do mniejszego wymiaru
        Warto≈õci bliskie 0 = bardzo podobne
        """
        if len(encoding1) != len(encoding2):
            print(f"‚ö†Ô∏è WARNING: Dimension mismatch - {len(encoding1)} vs {len(encoding2)}")
            # Przycina do mniejszego wymiaru
            min_dim = min(len(encoding1), len(encoding2))
            encoding1 = encoding1[:min_dim]
            encoding2 = encoding2[:min_dim]
            print(f"‚úÇÔ∏è Truncated to {min_dim} dimensions")
        
        return np.linalg.norm(encoding1 - encoding2)


def main():
    """G≈Ç√≥wna funkcja do testowania"""
    print("\nüé≠ Advanced Face Recognition System - Test Mode\n")

    # Inicjalizuj rozpoznawacz
    recognizer = FaceRecognizer()

    # Pobierz argumenty z linii polece≈Ñ
    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "register" and len(sys.argv) > 3:
            pesel = sys.argv[2]
            photo_path = sys.argv[3]
            result = recognizer.register_person(pesel, photo_path)
            print(json.dumps({"success": result}))

        elif command == "recognize" and len(sys.argv) > 2:
            image_path = sys.argv[2]
            result = recognizer.recognize_face(image_path)
            print(json.dumps(result, default=str))

        else:
            print("Usage:")
            print("  python face_recognition.py register <pesel> <photo_path>")
            print("  python face_recognition.py recognize <image_path>")
    else:
        print("Usage:")
        print("  python face_recognition.py register <pesel> <photo_path>")
        print("  python face_recognition.py recognize <image_path>")


if __name__ == "__main__":
    main()